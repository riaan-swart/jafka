# datastream.scratch.riaan-app.partitioningDepth = 0
# datastream.stream.fakenews_twitter_kpis_live.cluster = /tt
# datastream.stream.dshdemoshared.partitioner = topic-level-partitioner
# datastream.stream.icasa_video_results.replication = 3
# datastream.internal.fakenews_twitter_scored.partitions = 1
# datastream.scratch.duptest.partitioningDepth = 0
# datastream.stream.speed.partitioningDepth = 12
# datastream.scratch.flinkjob-test.write = scratch.flinkjob-test.dshdemo
# datastream.stream.dsc-bootstrap-predicted-amt-callers-15m.partitioner = topic-level-partitioner
# datastream.internal.fakenews_twitter_ingest.partitioningDepth = 0
# datastream.stream.ov-bicycle.read = stream\\.ov-bicycle\\.[^.]*
# datastream.internal.fakenews_twitter_ingest_live.write = internal.fakenews_twitter_ingest_live.dshdemo
# datastream.stream.fakenews_twitter_ingest_dynamic.cluster = /tt
# datastream.stream.fakenews_twitter_ingest_dynamic.write = stream.fakenews_twitter_ingest_dynamic.dshdemo
# datastream.stream.dsc-bootstrap-predicted-wait-15m.read = stream\\.dsc-bootstrap-predicted-wait-15m\\.[^.]*
# datastream.stream.pong.cluster = /tt
# datastream.stream.a-telemetry.replication = 1
# datastream.stream.fakenews_twitter_kpis.read = stream\\.fakenews_twitter_kpis\\.[^.]*
# datastream.stream.dsc-bootstrap-predicted-wait-15m.write = stream.dsc-bootstrap-predicted-wait-15m.dshdemo
# datastream.stream.dshdemoshared.cluster = /tt
# datastream.internal.testprops.replication = 3
# datastream.stream.spdp-stat_tp_v1.partitioningDepth = 12
# datastream.stream.dshdemoshared.replication = 3
# datastream.stream.fakenews_twitter_kpis_live.partitions = 1
# datastream.stream.dsc-bootstrap-predicted-wait-15m.partitions = 1
# datastream.stream.dsc-bootstrap-wait-time.partitions = 1
# datastream.scratch.riaan-app.replication = 3
# datastream.stream.node-red-dsh.partitioner = topic-level-partitioner
# datastream.stream.map5g_wrapped.write = stream.map5g_wrapped.dshdemo
# datastream.stream.airpollution.partitioningDepth = 12
# datastream.stream.dsc-bootstrap-predicted-wait-5m.read = stream\\.dsc-bootstrap-predicted-wait-5m\\.[^.]*
# datastream.stream.colorspeed.write = stream.colorspeed.dshdemo
# datastream.stream.mqtt-test.replication = 3
# datastream.stream.testmultiple.canretain = true
# datastream.stream.garbage2.write = stream.garbage2.dshdemo
# datastream.stream.service-health-metrics.write = stream.service-health-metrics.dshdemo
# datastream.stream.ov-bicycle.write = stream.ov-bicycle.dshdemo
# datastream.internal.fakenews_twitter_ingest_live.partitioner = default-partitioner
# datastream.scratch.knvb-input2.replication = 1
# datastream.stream.spat5g.partitions = 12
# datastream.stream.service-health-metrics.canretain = true
# datastream.stream.kafka-load.partitions = 12
# datastream.stream.pang.partitioner = topic-level-partitioner
# datastream.internal.fakenews_twitter_ingest.partitions = 1
# datastream.stream.mqtt-test.write = stream.mqtt-test.dshdemo
# datastream.stream.satellite.partitioner = topic-level-partitioner
# datastream.stream.dsc-bootstrap-wait-time.cluster = /tt
# datastream.internal.a-callcenter-logs.partitions = 1
# datastream.stream.garbage2.partitions = 12
# datastream.stream.dshdemoshared.write = stream.dshdemoshared.dshdemo
# datastream.stream.chaos-pecos.cluster = /tt
# datastream.internal.fakenews_twitter_scored_live.canretain = false
# datastream.stream.spat5g.canretain = false
# datastream.stream.airpollution.partitions = 12
# datastream.internal.testprops.cluster = /tt
# datastream.stream.ov-kv6.partitions = 12
# datastream.stream.puppeteer.partitioner = topic-level-partitioner
# datastream.scratch.stesbtest.canretain = false
# datastream.stream.node-red-dsh.replication = 3
# datastream.stream.fakenews_twitter_kpis_live.read = stream\\.fakenews_twitter_kpis_live\\.[^.]*
# datastream.internal.testprops2.canretain = false
# datastream.stream.dsc-bootstrap-predicted-amt-queuers-15m.replication = 1
# datastream.scratch.eztest.partitioningDepth = 0
# datastream.scratch.timtest.partitioner = default-partitioner
# datastream.stream.pong.partitions = 12
# datastream.stream.speed.write = stream.speed.dshdemo
# datastream.scratch.knvb-input2.cluster = /tt
# datastream.scratch.knvb-input2.partitioningDepth = 0
# datastream.stream.spdp-stat_vp_v1.partitioningDepth = 12
# datastream.stream.platform-mgmt.canretain = true
# datastream.stream.fakenews_twitter_kpis_live.partitioner = default-partitioner
# datastream.stream.fakenews_twitter_kpis_live.partitioningDepth = 0
# datastream.internal.a-callcenter-logs.canretain = false
# datastream.stream.cam5g.replication = 1
# datastream.stream.spdp-stat_tp_v2.cluster = /tt
# datastream.stream.metrics.cluster = /tt
# datastream.stream.cam5g-json.canretain = false
# datastream.stream.cam5g-json.partitioningDepth = 12
# datastream.stream.dshdemoshared.partitioningDepth = 1
# datastream.stream.map5g-json.canretain = true
# datastream.stream.railsense.replication = 3
# datastream.stream.ping.partitioner = topic-level-partitioner
# datastream.scratch.timtest.replication = 1
# datastream.stream.file_beacon.write = stream.file_beacon.dshdemo
# datastream.stream.a-dashboard.partitioner = topic-level-partitioner
# datastream.stream.blabberutest.write = stream.blabberutest.dshdemo
# datastream.scratch.knvb-output.write = scratch.knvb-output.dshdemo
# datastream.stream.weather.cluster = /tt
# datastream.stream.ping.cluster = /tt
# datastream.stream.testmultiple.cluster = /tt
# datastream.stream.screenshotter.partitioner = topic-level-partitioner
# datastream.internal.fakenews_twitter_ingest.partitioner = default-partitioner
# datastream.stream.dawson.partitions = 1
# datastream.stream.dsc-bootstrap-wait-time.replication = 1
# datastream.stream.dynamic_twitter_keywords.partitions = 1
# datastream.scratch.duptest.read = scratch.duptest.dshdemo
# datastream.stream.dsc-bootstrap-predicted-amt-queuers-15m.read = stream\\.dsc-bootstrap-predicted-amt-queuers-15m\\.[^.]*
# datastream.stream.colorspeed.partitioningDepth = 12
# datastream.stream.elbowgrease-firehose.write = stream.elbowgrease-firehose.dshdemo
# datastream.stream.dsc-bootstrap-queuers-per-service.cluster = /tt
# datastream.stream.service-health-metrics.replication = 2
# datastream.stream.fakenews_twitter_kpis.replication = 3
# datastream.stream.mqtt-test.read = stream\\.mqtt-test\\.[^.]*
# datastream.scratch.eztest.replication = 3
# datastream.stream.spdp-stat_vp_v2.canretain = true
# datastream.scratch.sastest.read = scratch.sastest.dshdemo
# datastream.stream.cam5g.partitioningDepth = 12
# datastream.stream.abc.read = stream\\.abc\\.[^.]*
# datastream.stream.screenshotter.canretain = true
# datastream.scratch.stesbtest.write = scratch.stesbtest.dshdemo
# datastream.stream.dynamic_twitter_keywords.partitioningDepth = 0
# datastream.stream.dsc-bootstrap-predicted-amt-callers-15m.read = stream\\.dsc-bootstrap-predicted-amt-callers-15m\\.[^.]*
# datastream.stream.pang.canretain = false
# datastream.stream.dsc-bootstrap-queuers-per-service.write = stream.dsc-bootstrap-queuers-per-service.dshdemo
# datastream.stream.dsc-bootstrap-predicted-wait-15m.partitioner = topic-level-partitioner
# datastream.stream.map5g-json.partitioner = topic-level-partitioner
# datastream.stream.icasa_epi_results.canretain = false
# datastream.internal.tenant-events-dshdemo.replication = 3
# datastream.stream.blabberutest.cluster = /tt
# datastream.internal.fakenews_twitter_scored.partitioningDepth = 0
# datastream.scratch.riaan-app.partitioner = default-partitioner
# datastream.internal.a-outages.partitions = 1
# datastream.stream.dsc-bootstrap-queuers-per-service.canretain = false
# datastream.stream.a-dashboard.replication = 1
# datastream.stream.map5g-json.replication = 3
# datastream.stream.blabberutest.partitions = 12
# datastream.stream.puppeteer.read = stream\\.puppeteer\\.[^.]*
# datastream.stream.railsense.canretain = true
# datastream.stream.spat5g-json.write = stream.spat5g-json.dshdemo
# datastream.stream.node-red-dsh.read = stream\\.node-red-dsh\\.[^.]*
# datastream.stream.fakenews_twitter_ingest_dynamic.canretain = false
# datastream.stream.map5g_wrapped.partitioner = topic-level-partitioner
# datastream.stream.cam5g-json.partitioner = topic-level-partitioner
# datastream.stream.kafka-load.partitioner = topic-level-partitioner
# datastream.internal.fakenews_twitter_scored.partitioner = default-partitioner
# datastream.stream.platform-mgmt.partitioningDepth = 2
# datastream.stream.garbage.partitions = 12
# datastream.scratch.eztest.partitions = 1
# datastream.internal.testprops.canretain = false
# datastream.internal.fakenews_twitter_ingest_live.partitions = 1
# datastream.scratch.knvb-output.cluster = /tt
# datastream.scratch.riaan-app.partitions = 1
# datastream.stream.node-red-dsh.partitioningDepth = 12
# datastream.scratch.knvb-input2.partitions = 1
# datastream.scratch.flinkjob-test.canretain = false
# datastream.stream.ping.partitions = 12
# datastream.stream.garbage2.partitioner = topic-level-partitioner
# datastream.stream.dsc-bootstrap-average-handling-time.partitioningDepth = 1
# envelope.streams = 
# datastream.stream.spdp-stat_tp_v2.read = stream\\.spdp-stat_tp_v2\\.[^.]*
# datastream.stream.pang.partitions = 12
# datastream.stream.kafkaheadertest.canretain = true
# datastream.stream.abc.cluster = /tt
# datastream.scratch.ksqltest.replication = 3
# datastream.stream.metrics.canretain = true
# datastream.stream.metrics.read = stream\\.metrics\\.[^.]*
# datastream.internal.testprops.partitions = 1
# datastream.stream.spdp-stat_tp_v1.replication = 3
# datastream.stream.icasa_video_results.write = stream.icasa_video_results.dshdemo
# datastream.stream.dsc-bootstrap-predicted-wait-5m.write = stream.dsc-bootstrap-predicted-wait-5m.dshdemo
# consumerGroups.private = dshdemo_riaan-app.fc2b369e-b125-11ed-86fe-70b3d5800002_1,dshdemo_riaan-app.fc2b369e-b125-11ed-86fe-70b3d5800002_2,dshdemo_riaan-app.fc2b369e-b125-11ed-86fe-70b3d5800002_3,dshdemo_riaan-app.fc2b369e-b125-11ed-86fe-70b3d5800002_4
# datastream.internal.fakenews_twitter_scored.read = internal\\.fakenews_twitter_scored\\.[^.]*
# datastream.scratch.knvb-input2.canretain = false
# datastream.stream.dsc-bootstrap-predicted-amt-queuers-15m.partitioner = topic-level-partitioner
# datastream.stream.airpollution.canretain = true
# datastream.internal.fakenews_twitter_ingest.write = internal.fakenews_twitter_ingest.dshdemo
# datastream.stream.dsc-bootstrap-predicted-wait-15m.canretain = false
# datastream.stream.dsc-bootstrap-wait-time.canretain = false
# datastream.internal.tenant-events-dshdemo.cluster = /tt
# datastream.stream.resource-state.partitioner = topic-level-partitioner
# datastream.stream.resource-state.partitioningDepth = 1
# datastream.stream.fakenews_twitter_kpis.partitioner = default-partitioner
# datastream.stream.dsc-bootstrap-predicted-wait-5m.partitioner = topic-level-partitioner
# datastream.stream.screenshotter.partitioningDepth = 1
# datastream.internal.people-anomalies.read = internal\\.people-anomalies\\.[^.]*
# datastream.stream.spdp-stat_vp_v1.cluster = /tt
# datastream.stream.colorspeed.partitions = 12
# datastream.internal.fakenews_twitter_ingest.replication = 3
# datastream.stream.metrics-druid.cluster = /tt
# datastream.scratch.sastest.write = scratch.sastest.dshdemo
# datastream.stream.node-red-dsh.canretain = true
# datastream.internal.a-callcenter-logs.replication = 1
# datastream.stream.spat5g.replication = 3
# datastream.stream.colorspeed2.replication = 3
# datastream.stream.dawson.canretain = true
# datastream.stream.screenshotter.cluster = /tt
# datastream.stream.mqtt-test.partitioningDepth = 12
# datastream.stream.testmultiple.read = stream\\.testmultiple\\.[^.]*
# datastream.scratch.knvb-input1.replication = 1
# datastream.stream.platform-mgmt.read = stream\\.platform-mgmt\\.[^.]*
# datastream.stream.spdp-stat_vp_v1.canretain = true
# datastream.scratch.ksqltest.read = scratch.ksqltest.dshdemo
# datastream.stream.spdp-stat_tp_v2.partitioningDepth = 12
# datastream.stream.spdp-stat_vp_v1.replication = 3
# datastream.stream.spdp-stat_vp_v1.read = stream\\.spdp-stat_vp_v1\\.[^.]*
# datastream.stream.metrics.write = stream.metrics.dshdemo
# datastream.stream.cam5g-json.cluster = /tt
# datastream.stream.ov-bicycle.partitioner = topic-level-partitioner
# datastream.stream.platform-mgmt.replication = 3
# datastream.stream.pong.canretain = false
# datastream.stream.node-red-dsh.write = stream.node-red-dsh.dshdemo
# datastream.stream.map5g.read = stream\\.map5g\\.[^.]*
# datastream.stream.node-red-dsh.cluster = /tt
# datastream.internal.a-outages.partitioningDepth = 0
# datastream.stream.dsc-bootstrap-queuers-per-service.partitions = 1
# datastream.stream.a-dashboard.canretain = true
# datastream.stream.a-dashboard.read = stream\\.a-dashboard\\.[^.]*
# datastream.stream.dsc-bootstrap-average-handling-time.partitions = 1
# datastream.stream.ov-bicycle.canretain = true
# datastream.scratch.knvb-output.partitioningDepth = 0
# datastream.stream.speed.canretain = false
# datastream.stream.node-red-dsh.partitions = 12
# datastream.stream.file_beacon.cluster = /tt
# datastream.stream.spdp-stat_tp_v1.cluster = /tt
# datastream.stream.dsc-bootstrap-queuers-and-callers.canretain = false
# datastream.stream.cam5g.partitioner = topic-level-partitioner
# datastream.stream.dsc-bootstrap-predicted-wait-5m.cluster = /tt
# datastream.stream.spat5g-json.replication = 3
# datastream.scratch.knvb-input2.read = scratch.knvb-input2.dshdemo
# datastream.stream.dsc-bootstrap-predicted-amt-callers-15m.cluster = /tt
# datastream.internal.fakenews_twitter_scored_live.partitioner = default-partitioner
# datastream.stream.map5g_wrapped.cluster = /tt
# datastream.stream.kafka-load.replication = 3
# datastream.stream.ov-kv6.partitioningDepth = 12
# datastream.stream.pong.partitioner = topic-level-partitioner
# datastream.stream.garbage.write = stream.garbage.dshdemo
# datastream.stream.dsc-bootstrap-queuers-and-callers.partitions = 1
# datastream.stream.dawson.partitioningDepth = 1
# datastream.stream.screenshotter.read = stream\\.screenshotter\\.[^.]*
# datastream.stream.cam5g-json.read = stream\\.cam5g-json\\.[^.]*
# datastream.stream.icasa_video_results.partitioningDepth = 0
# datastream.stream.dawson.partitioner = topic-level-partitioner
# datastream.internal.fakenews_twitter_ingest_live.cluster = /tt
# datastream.internal.a-callcenter-logs.cluster = /tt
# datastream.scratch.timtest.write = scratch.timtest.dshdemo
# datastream.stream.file_beacon.partitions = 1
# datastream.stream.blabberutest.replication = 3
# datastream.scratch.ksqltest.canretain = false
# datastream.stream.dsc-bootstrap-wait-time.write = stream.dsc-bootstrap-wait-time.dshdemo
# datastream.scratch.stesbtest.cluster = /tt
# datastream.stream.dsc-bootstrap-predicted-amt-callers-15m.canretain = false
# datastream.stream.a-telemetry.cluster = /tt
# datastream.stream.fakenews_twitter_ingest_dynamic.partitioner = topic-level-partitioner
# datastream.stream.file_beacon.partitioningDepth = 0
# datastream.stream.icasa_video_results.cluster = /tt
# datastream.stream.dsc-bootstrap-predicted-amt-queuers-15m.write = stream.dsc-bootstrap-predicted-amt-queuers-15m.dshdemo
# datastream.stream.metrics-druid.partitioningDepth = 1
# datastream.stream.map5g.replication = 3
# datastream.stream.map5g-json.cluster = /tt
# datastream.stream.puppeteer.write = stream.puppeteer.dshdemo
# datastream.stream.dsc-bootstrap-predicted-amt-callers-15m.partitioningDepth = 1
# datastream.stream.resource-request-state.read = stream\\.resource-request-state\\.[^.]*
# datastream.stream.fakenews_twitter_kpis.partitions = 1
# datastream.stream.airpollution.write = stream.airpollution.dshdemo
# datastream.stream.metrics-druid.partitions = 3
# datastream.stream.platform-mgmt.partitioner = topic-level-partitioner
# datastream.stream.fakenews_twitter_kpis.write = stream.fakenews_twitter_kpis.dshdemo
# datastream.stream.elbowgrease-firehose.read = stream\\.elbowgrease-firehose\\.[^.]*
# datastream.scratch.timtest.read = scratch.timtest.dshdemo
# datastream.scratch.knvb-input2.write = scratch.knvb-input2.dshdemo
# datastream.internal.fakenews_twitter_scored_live.partitioningDepth = 0
# datastream.stream.cam5g-json.replication = 3
# datastream.internal.fakenews_twitter_ingest_live.partitioningDepth = 0
# datastream.stream.colorspeed.partitioner = topic-level-partitioner
# datastream.stream.a-dashboard.cluster = /tt
# datastream.stream.abc.replication = 3
# datastream.stream.dawson.replication = 3
# datastream.stream.railsense.cluster = /tt
# datastream.internal.fakenews_twitter_ingest_live.read = internal\\.fakenews_twitter_ingest_live\\.[^.]*
# datastream.stream.spdp-stat_tp_v2.partitions = 1
# datastream.stream.resource-state.canretain = true
# datastream.stream.resource-request-state.cluster = /tt
# datastream.stream.fakenews_twitter_kpis.cluster = /tt
# datastream.stream.elbowgrease-firehose.partitions = 1
# datastream.internal.a-outages.canretain = false
# datastream.stream.ping.write = stream.ping.dshdemo
# datastream.stream.dsc-bootstrap-queuers-per-service.read = stream\\.dsc-bootstrap-queuers-per-service\\.[^.]*
# datastream.stream.satellite.write = stream.satellite.dshdemo
# datastream.stream.service-health-metrics.partitions = 4
# datastream.stream.icasa_video_results.partitions = 1
# datastream.stream.spat5g-json.canretain = false
# datastream.internal.a-callcenter-logs.read = internal\\.a-callcenter-logs\\.[^.]*
# datastream.stream.pang.partitioningDepth = 1
# datastream.stream.spdp-stat_vp_v1.partitions = 1
# datastream.stream.kafka-load.cluster = /tt
# datastream.stream.dsc-bootstrap-queuers-and-callers.replication = 1
# datastream.stream.icasa_epi_results.partitioner = default-partitioner
# datastream.stream.metrics.partitioner = topic-level-partitioner
# datastream.stream.satellite.partitioningDepth = 12
# datastream.stream.fakenews_twitter_kpis.canretain = false
# datastream.stream.ov-kv6.cluster = /tt
# datastream.stream.ov-kv6.partitioner = topic-level-partitioner
# datastream.stream.garbage.partitioner = topic-level-partitioner
# datastream.stream.elbowgrease-firehose.canretain = true
# datastream.internal.testprops.write = internal.testprops.dshdemo
# datastream.stream.spdp-stat_vp_v2.replication = 3
# datastream.stream.testmultiple.partitioningDepth = 3
# datastream.stream.garbage2.cluster = /tt
# datastream.scratch.riaan-app.canretain = false
# datastream.internal.tenant-events-dshdemo.canretain = false
# datastream.stream.dynamic_twitter_keywords.canretain = false
# datastream.internal.testprops2.partitions = 1
# datastream.stream.map5g.cluster = /tt
# datastream.stream.icasa_epi_results.cluster = /tt
# datastream.scratch.ksqltest.partitions = 1
# datastream.stream.spat5g-json.cluster = /tt
# datastream.stream.spat5g-json.partitioningDepth = 1
# datastream.stream.metrics.replication = 2
# datastream.stream.airpollution.read = stream\\.airpollution\\.[^.]*
# datastream.stream.metrics-druid.write = stream.metrics-druid.dshdemo
# datastream.stream.dsc-bootstrap-queuers-per-service.partitioningDepth = 1
# datastream.internal.fakenews_twitter_scored_live.replication = 3
# datastream.stream.metrics.partitions = 4
# datastream.stream.metrics-druid.read = stream\\.metrics-druid\\.[^.]*
# datastream.stream.dsc-bootstrap-queuers-per-service.partitioner = topic-level-partitioner
# datastream.stream.satellite.read = stream\\.satellite\\.[^.]*
# datastream.stream.dsc-bootstrap-average-handling-time.replication = 1
# datastream.scratch.flinkjob-test.replication = 1
# datastream.internal.testprops2.cluster = /tt
# datastream.internal.a-outages.cluster = /tt
# datastream.stream.garbage2.replication = 3
# datastream.stream.blabberutest.read = stream\\.blabberutest\\.[^.]*
# datastream.internal.fakenews_twitter_scored.write = internal.fakenews_twitter_scored.dshdemo
# datastream.scratch.riaan-app.read = scratch.riaan-app.dshdemo
# datastream.stream.resource-state.cluster = /tt
# datastream.scratch.sastest.cluster = /tt
# datastream.stream.service-health-metrics.read = stream\\.service-health-metrics\\.[^.]*
# datastream.stream.abc.partitions = 1
# datastream.stream.map5g-json.write = stream.map5g-json.dshdemo
# datastream.scratch.ksqltest.partitioner = default-partitioner
# datastream.scratch.stesbtest.partitioningDepth = 0
# datastream.scratch.knvb-input2.partitioner = default-partitioner
# datastream.internal.tenant-events-dshdemo.partitions = 1
# datastream.internal.fakenews_twitter_ingest.cluster = /tt
# datastream.stream.ov-bicycle.partitioningDepth = 12
# consumerGroups.shared = dshdemo_riaan-app_1,dshdemo_riaan-app_2,dshdemo_riaan-app_3,dshdemo_riaan-app_4
# datastream.stream.chaos-pecos.partitioningDepth = 1
# datastream.stream.a-telemetry.partitions = 1
# datastream.stream.elbowgrease-firehose.replication = 3
# datastream.stream.garbage.canretain = true
# datastream.stream.airpollution.partitioner = topic-level-partitioner
# datastream.stream.icasa_epi_results.partitions = 1
# datastream.stream.dynamic_twitter_keywords.read = stream\\.dynamic_twitter_keywords\\.[^.]*
# datastream.scratch.flinkjob-test.partitioningDepth = 0
# datastream.stream.spdp-stat_tp_v2.replication = 3
# datastream.internal.a-callcenter-logs.partitioner = default-partitioner
# datastream.internal.fakenews_twitter_scored_live.read = internal\\.fakenews_twitter_scored_live\\.[^.]*
# datastream.stream.dsc-bootstrap-predicted-wait-15m.cluster = /tt
# datastream.internal.tenant-events-dshdemo.read = internal\\.tenant-events-dshdemo\\.[^.]*
# datastream.internal.a-outages.partitioner = default-partitioner
# datastream.scratch.knvb-input1.read = scratch.knvb-input1.dshdemo
# datastream.stream.dsc-bootstrap-predicted-amt-queuers-15m.partitions = 1
# datastream.stream.dshdemoshared.canretain = true
# datastream.stream.dsc-bootstrap-queuers-and-callers.write = stream.dsc-bootstrap-queuers-and-callers.dshdemo
# datastream.stream.puppeteer.cluster = /tt
# datastream.stream.weather.partitioningDepth = 12
# datastream.internal.a-callcenter-logs.partitioningDepth = 0
# datastream.stream.airpollution.replication = 3
# datastream.scratch.eztest.canretain = false
# datastream.stream.dsc-bootstrap-predicted-wait-15m.partitioningDepth = 1
# datastream.stream.dsc-bootstrap-queuers-and-callers.partitioningDepth = 1
# datastream.internal.fakenews_twitter_ingest_live.canretain = false
# datastream.stream.dynamic_twitter_keywords.partitioner = default-partitioner
# datastream.stream.map5g_wrapped.partitioningDepth = 12
# datastream.stream.ping.canretain = true
# datastream.stream.colorspeed2.canretain = true
# datastream.stream.dsc-bootstrap-predicted-wait-15m.replication = 1
# datastream.internal.people-anomalies.replication = 1
# datastream.stream.resource-request-state.partitioningDepth = 1
# datastream.stream.metrics.partitioningDepth = 2
# datastream.stream.ov-kv6.read = stream\\.ov-kv6\\.[^.]*
# datastream.stream.icasa_video_results.partitioner = default-partitioner
# datastream.scratch.knvb-output.read = scratch.knvb-output.dshdemo
# datastream.stream.weather.replication = 3
# datastream.stream.chaos-pecos.canretain = true
# datastream.internal.fakenews_twitter_scored_live.write = internal.fakenews_twitter_scored_live.dshdemo
# datastream.stream.fakenews_twitter_ingest_dynamic.replication = 1
# datastream.stream.colorspeed.read = stream\\.colorspeed\\.[^.]*
# datastream.stream.ping.replication = 3
# datastream.scratch.flinkjob-test.cluster = /tt
# datastream.scratch.flinkjob-test.read = scratch.flinkjob-test.dshdemo
# datastream.stream.a-dashboard.partitioningDepth = 1
# datastream.stream.puppeteer.replication = 1
# datastream.internal.fakenews_twitter_scored.canretain = false
# datastream.stream.file_beacon.read = stream\\.file_beacon\\.[^.]*
# datastream.stream.satellite.replication = 3
# datastream.stream.icasa_epi_results.read = stream\\.icasa_epi_results\\.[^.]*
# datastream.scratch.stesbtest.replication = 3
# datastream.stream.dsc-bootstrap-predicted-wait-5m.partitioningDepth = 1
# datastream.stream.ov-kv6.canretain = true
# datastream.stream.cam5g.write = stream.cam5g.dshdemo
# datastream.stream.weather.partitions = 12
# datastream.stream.a-telemetry.canretain = true
# datastream.internal.fakenews_twitter_scored_live.partitions = 1
# datastream.stream.fakenews_twitter_ingest_dynamic.partitioningDepth = 1
# datastream.scratch.timtest.canretain = false
# datastream.scratch.sastest.partitioner = default-partitioner
# datastream.stream.satellite.cluster = /tt
# datastream.stream.kafkaheadertest.cluster = /tt
# datastream.stream.kafkaheadertest.read = stream\\.kafkaheadertest\\.[^.]*
# datastream.stream.testmultiple.replication = 3
# datastream.scratch.timtest.cluster = /tt
# datastream.stream.kafka-load.canretain = true
# datastream.internal.people-anomalies.partitioner = default-partitioner
# datastream.stream.dynamic_twitter_keywords.write = stream.dynamic_twitter_keywords.dshdemo
# datastream.stream.map5g_wrapped.partitions = 1
# datastream.internal.fakenews_twitter_ingest.canretain = false
# datastream.stream.kafkaheadertest.partitions = 1
# datastream.stream.satellite.canretain = true
# datastream.stream.resource-request-state.partitioner = topic-level-partitioner
# datastream.stream.spat5g.cluster = /tt
# datastream.stream.spdp-stat_vp_v2.partitioningDepth = 12
# datastream.stream.spdp-stat_tp_v1.read = stream\\.spdp-stat_tp_v1\\.[^.]*
# datastream.stream.map5g-json.partitions = 1
# datastream.stream.icasa_video_results.read = stream\\.icasa_video_results\\.[^.]*
# datastream.scratch.duptest.write = scratch.duptest.dshdemo
# datastream.internal.testprops2.write = internal.testprops2.dshdemo
# datastream.stream.chaos-pecos.partitioner = topic-level-partitioner
# datastream.stream.colorspeed2.write = stream.colorspeed2.dshdemo
# datastream.stream.testmultiple.write = stream.testmultiple.dshdemo
# datastream.stream.abc.write = stream.abc.dshdemo
# datastream.stream.dynamic_twitter_keywords.cluster = /tt
# datastream.stream.chaos-pecos.read = stream\\.chaos-pecos\\.[^.]*
# datastream.stream.spat5g.read = stream\\.spat5g\\.[^.]*
# datastream.stream.mqtt-test.partitioner = topic-level-partitioner
# datastream.stream.service-health-metrics.partitioningDepth = 2
# datastream.stream.ov-kv6.write = stream.ov-kv6.dshdemo
# datastream.stream.railsense.partitioner = topic-level-partitioner
# datastream.stream.railsense.write = stream.railsense.dshdemo
# datastream.internal.fakenews_twitter_scored.cluster = /tt
# datastream.stream.speed.partitions = 12
# datastream.stream.elbowgrease-firehose.partitioningDepth = 0
# datastream.stream.metrics-druid.partitioner = topic-level-partitioner
# datastream.stream.garbage2.partitioningDepth = 12
# datastream.stream.resource-state.read = stream\\.resource-state\\.[^.]*
# datastream.stream.map5g-json.partitioningDepth = 12
# datastream.internal.people-anomalies.partitioningDepth = 0
# datastream.scratch.flinkjob-test.partitions = 1
# datastream.stream.a-telemetry.read = stream\\.a-telemetry\\.[^.]*
# datastream.stream.mqtt-test.cluster = /tt
# datastream.scratch.eztest.cluster = /tt
# datastream.stream.map5g.canretain = true
# datastream.stream.file_beacon.canretain = false
# datastream.scratch.knvb-input1.partitions = 1
# datastream.stream.garbage.partitioningDepth = 12
# datastream.stream.resource-request-state.replication = 3
# datastream.stream.icasa_video_results.canretain = false
# datastream.stream.dsc-bootstrap-predicted-amt-callers-15m.write = stream.dsc-bootstrap-predicted-amt-callers-15m.dshdemo
# datastream.stream.chaos-pecos.replication = 1
# datastream.stream.garbage2.canretain = true
# datastream.internal.fakenews_twitter_ingest_live.replication = 3
# datastream.scratch.knvb-input1.partitioningDepth = 0
# datastream.scratch.knvb-output.partitions = 1
# datastream.stream.dsc-bootstrap-predicted-amt-queuers-15m.canretain = false
# datastream.stream.dsc-bootstrap-predicted-amt-queuers-15m.cluster = /tt
# datastream.internal.fakenews_twitter_scored_live.cluster = /tt
# datastream.stream.kafkaheadertest.replication = 3
# datastream.stream.cam5g-json.partitions = 12
# datastream.stream.garbage.read = stream\\.garbage\\.[^.]*
# datastream.stream.map5g.partitioningDepth = 12
# datastream.scratch.timtest.partitioningDepth = 0
# datastream.stream.dsc-bootstrap-predicted-wait-5m.canretain = false
# datastream.scratch.knvb-output.partitioner = default-partitioner
# datastream.stream.platform-mgmt.cluster = /tt
# datastream.stream.colorspeed.canretain = true
# datastream.stream.puppeteer.partitioningDepth = 1
# datastream.stream.dawson.write = stream.dawson.dshdemo
# datastream.stream.icasa_epi_results.write = stream.icasa_epi_results.dshdemo
# datastream.stream.platform-mgmt.partitions = 6
# datastream.stream.spdp-stat_tp_v2.canretain = true
# datastream.stream.dsc-bootstrap-predicted-amt-callers-15m.partitions = 1
# datastream.stream.pang.read = stream\\.pang\\.[^.]*
# datastream.stream.ping.read = stream\\.ping\\.[^.]*
# datastream.stream.file_beacon.replication = 3
# datastream.stream.dsc-bootstrap-average-handling-time.canretain = false
# datastream.scratch.duptest.cluster = /tt
# datastream.scratch.sastest.partitions = 1
# datastream.stream.kafka-load.read = stream\\.kafka-load\\.[^.]*
# datastream.stream.icasa_epi_results.partitioningDepth = 0
# datastream.scratch.riaan-app.cluster = /tt
# datastream.scratch.stesbtest.read = scratch.stesbtest.dshdemo
# datastream.stream.spdp-stat_vp_v1.partitioner = topic-level-partitioner
# datastream.stream.metrics-druid.canretain = true
# datastream.internal.testprops.partitioningDepth = 0
# datastream.stream.map5g-json.read = stream\\.map5g-json\\.[^.]*
# datastream.scratch.knvb-output.canretain = false
# datastream.scratch.ksqltest.write = scratch.ksqltest.dshdemo
# datastream.stream.resource-state.partitions = 6
# datastream.stream.file_beacon.partitioner = default-partitioner
# datastream.stream.colorspeed2.partitions = 12
# datastream.stream.puppeteer.canretain = true
# datastream.stream.ov-bicycle.partitions = 12
# datastream.stream.dynamic_twitter_keywords.replication = 3
# datastream.stream.airpollution.cluster = /tt
# datastream.stream.cam5g.cluster = /tt
# datastream.scratch.duptest.partitioner = default-partitioner
# datastream.internal.testprops2.replication = 3
# datastream.stream.pang.replication = 3
# datastream.stream.map5g_wrapped.replication = 3
# datastream.internal.testprops.read = internal\\.testprops\\.[^.]*
# datastream.scratch.timtest.partitions = 1
# datastream.stream.colorspeed2.partitioningDepth = 12
# datastream.stream.dsc-bootstrap-average-handling-time.write = stream.dsc-bootstrap-average-handling-time.dshdemo
# datastream.stream.dawson.cluster = /tt
# datastream.stream.dsc-bootstrap-average-handling-time.read = stream\\.dsc-bootstrap-average-handling-time\\.[^.]*
# datastream.stream.dsc-bootstrap-predicted-amt-callers-15m.replication = 1
# datastream.stream.chaos-pecos.write = stream.chaos-pecos.dshdemo
# datastream.stream.map5g.partitions = 1
# datastream.stream.colorspeed2.read = stream\\.colorspeed2\\.[^.]*
# datastream.scratch.sastest.partitioningDepth = 0
# datastream.stream.dsc-bootstrap-predicted-wait-5m.replication = 1
# datastream.stream.ov-kv6.replication = 3
# datastream.stream.ov-bicycle.cluster = /tt
# datastream.stream.abc.canretain = true
# datastream.scratch.ksqltest.partitioningDepth = 0
# datastream.scratch.stesbtest.partitions = 3
# datastream.stream.a-telemetry.partitioningDepth = 1
# datastream.stream.fakenews_twitter_ingest_dynamic.read = stream\\.fakenews_twitter_ingest_dynamic\\.[^.]*
# datastream.stream.resource-request-state.partitions = 6
# datastream.stream.kafkaheadertest.partitioner = default-partitioner
# datastream.stream.satellite.partitions = 4
# datastream.stream.screenshotter.partitions = 1
# datastream.stream.screenshotter.replication = 2
# datastream.stream.a-telemetry.partitioner = topic-level-partitioner
# datastream.stream.fakenews_twitter_ingest_dynamic.partitions = 1
# datastream.stream.spdp-stat_tp_v1.partitioner = topic-level-partitioner
# datastream.scratch.knvb-input1.canretain = false
# datastream.stream.dsc-bootstrap-wait-time.read = stream\\.dsc-bootstrap-wait-time\\.[^.]*
# datastream.stream.mqtt-test.canretain = false
# datastream.stream.map5g.write = stream.map5g.dshdemo
# datastream.stream.colorspeed2.partitioner = topic-level-partitioner
# datastream.stream.service-health-metrics.partitioner = topic-level-partitioner
# datastream.stream.dsc-bootstrap-predicted-wait-5m.partitions = 1
# datastream.internal.tenant-events-dshdemo.partitioningDepth = 0
# datastream.stream.map5g_wrapped.read = stream\\.map5g_wrapped\\.[^.]*
# datastream.stream.dsc-bootstrap-queuers-and-callers.cluster = /tt
# datastream.stream.blabberutest.canretain = true
# datastream.stream.railsense.read = stream\\.railsense\\.[^.]*
# datastream.stream.dsc-bootstrap-wait-time.partitioningDepth = 1
# datastream.stream.weather.write = stream.weather.dshdemo
# datastream.internal.tenant-events-dshdemo.partitioner = default-partitioner
# datastream.stream.testmultiple.partitioner = topic-level-partitioner
# datastream.stream.abc.partitioner = default-partitioner
# datastream.stream.dsc-bootstrap-queuers-and-callers.read = stream\\.dsc-bootstrap-queuers-and-callers\\.[^.]*
# datastream.stream.spdp-stat_tp_v1.canretain = true
# datastream.scratch.knvb-input1.partitioner = default-partitioner
# datastream.scratch.ksqltest.cluster = /tt
# datastream.scratch.duptest.canretain = false
# datastream.stream.garbage.cluster = /tt
# datastream.stream.weather.read = stream\\.weather\\.[^.]*
# datastream.stream.chaos-pecos.partitions = 1
# datastream.stream.colorspeed.replication = 3
# datastream.stream.dshdemoshared.read = stream\\.dshdemoshared\\.[^.]*
# datastream.stream.dsc-bootstrap-wait-time.partitioner = topic-level-partitioner
# datastream.stream.pong.partitioningDepth = 1
# datastream.stream.speed.partitioner = topic-level-partitioner
# datastream.internal.people-anomalies.canretain = false
# datastream.scratch.eztest.read = scratch.eztest.dshdemo
# datastream.stream.cam5g.partitions = 12
# datastream.scratch.duptest.replication = 3
# datastream.scratch.eztest.write = scratch.eztest.dshdemo
# datastream.stream.spdp-stat_vp_v2.cluster = /tt
# datastream.stream.spdp-stat_vp_v2.read = stream\\.spdp-stat_vp_v2\\.[^.]*
# datastream.scratch.sastest.canretain = false
# datastream.stream.dsc-bootstrap-average-handling-time.partitioner = topic-level-partitioner
# datastream.stream.weather.partitioner = topic-level-partitioner
# datastream.stream.dsc-bootstrap-queuers-per-service.replication = 1
# datastream.stream.speed.cluster = /tt
# datastream.stream.spat5g-json.partitions = 12
# datastream.internal.testprops2.read = internal\\.testprops2\\.[^.]*
# datastream.stream.spdp-stat_tp_v2.partitioner = topic-level-partitioner
# datastream.stream.colorspeed.cluster = /tt
# datastream.stream.ov-bicycle.replication = 3
# datastream.stream.spat5g-json.read = stream\\.spat5g-json\\.[^.]*
# datastream.stream.pang.cluster = /tt
# datastream.stream.spat5g.partitioningDepth = 1
# datastream.internal.fakenews_twitter_ingest.read = internal\\.fakenews_twitter_ingest\\.[^.]*
# datastream.stream.metrics-druid.replication = 1
# datastream.stream.cam5g.read = stream\\.cam5g\\.[^.]*
# datastream.scratch.stesbtest.partitioner = default-partitioner
# datastream.stream.map5g_wrapped.canretain = true
# datastream.stream.pong.replication = 3
# datastream.stream.spat5g-json.partitioner = topic-level-partitioner
# datastream.stream.dawson.read = stream\\.dawson\\.[^.]*
# datastream.scratch.knvb-output.replication = 1
# datastream.stream.pong.write = stream.pong.dshdemo
# datastream.stream.speed.replication = 3
# datastream.internal.people-anomalies.partitions = 1
# datastream.stream.service-health-metrics.cluster = /tt
# datastream.stream.railsense.partitions = 4
# datastream.stream.fakenews_twitter_kpis_live.write = stream.fakenews_twitter_kpis_live.dshdemo
# datastream.internal.testprops2.partitioner = default-partitioner
# datastream.stream.resource-state.replication = 3
# datastream.stream.spat5g.partitioner = topic-level-partitioner
# datastream.stream.map5g.partitioner = topic-level-partitioner
# datastream.stream.a-dashboard.partitions = 1
# datastream.internal.a-outages.read = internal\\.a-outages\\.[^.]*
# datastream.stream.mqtt-test.partitions = 1
# datastream.scratch.sastest.replication = 3
# datastream.stream.dsc-bootstrap-queuers-and-callers.partitioner = topic-level-partitioner
# datastream.stream.cam5g.canretain = false
# datastream.internal.testprops2.partitioningDepth = 0
# datastream.internal.testprops.partitioner = default-partitioner
# datastream.stream.dsc-bootstrap-average-handling-time.cluster = /tt
# datastream.scratch.riaan-app.write = scratch.riaan-app.dshdemo
# datastream.stream.fakenews_twitter_kpis_live.canretain = false
# datastream.scratch.flinkjob-test.partitioner = default-partitioner
# datastream.stream.pang.write = stream.pang.dshdemo
# datastream.stream.cam5g-json.write = stream.cam5g-json.dshdemo
# datastream.stream.kafka-load.partitioningDepth = 1
# datastream.stream.blabberutest.partitioningDepth = 1
# datastream.stream.abc.partitioningDepth = 0
# datastream.stream.garbage.replication = 3
# datastream.stream.weather.canretain = true
# datastream.internal.a-outages.replication = 1
# datastream.scratch.eztest.partitioner = default-partitioner
# datastream.stream.spdp-stat_vp_v2.partitioner = topic-level-partitioner
# datastream.stream.colorspeed2.cluster = /tt
# datastream.stream.garbage2.read = stream\\.garbage2\\.[^.]*
# datastream.stream.icasa_epi_results.replication = 3
# datastream.stream.spat5g.write = stream.spat5g.dshdemo
# datastream.stream.elbowgrease-firehose.cluster = /tt
# datastream.stream.dshdemoshared.partitions = 1
# datastream.scratch.duptest.partitions = 3
# datastream.stream.speed.read = stream\\.speed\\.[^.]*
# datastream.stream.fakenews_twitter_kpis.partitioningDepth = 0
# datastream.stream.elbowgrease-firehose.partitioner = default-partitioner
# datastream.stream.kafkaheadertest.write = stream.kafkaheadertest.dshdemo
# datastream.stream.spdp-stat_tp_v1.partitions = 1
# datastream.stream.blabberutest.partitioner = topic-level-partitioner
# datastream.internal.people-anomalies.cluster = /tt
# datastream.stream.fakenews_twitter_kpis_live.replication = 3
# datastream.stream.resource-request-state.canretain = true
# datastream.stream.ping.partitioningDepth = 1
# datastream.stream.testmultiple.partitions = 12
# datastream.stream.railsense.partitioningDepth = 12
# datastream.scratch.knvb-input1.cluster = /tt
# datastream.internal.fakenews_twitter_scored.replication = 3
# datastream.stream.kafkaheadertest.partitioningDepth = 0
# datastream.stream.screenshotter.write = stream.screenshotter.dshdemo
# datastream.scratch.knvb-input1.write = scratch.knvb-input1.dshdemo
# datastream.stream.dsc-bootstrap-predicted-amt-queuers-15m.partitioningDepth = 1
# datastream.stream.spdp-stat_vp_v2.partitions = 1
# datastream.stream.puppeteer.partitions = 1

bootstrap.servers = riaan-proxy-0.kafka.dshdemo.dev.kpn-dsh.com:9091,riaan-proxy-1.kafka.dshdemo.dev.kpn-dsh.com:9091,riaan-proxy-2.kafka.dshdemo.dev.kpn-dsh.com:9091

# a default consumer group, can be overridden
group.id=dshdemo_riaan-app_1

# # https://github.com/confluentinc/librdkafka/wiki/Using-SSL-with-librdkafka
# security.protocol=SSL
# # CA certificate file for verifying the broker's certificate.
# ssl.ca.location=/home/riaan/dev/certstrap/out/RiaanInc.crt
# # Client's certificate
# ssl.certificate.location=/home/riaan/dev/certstrap/out/client.of.brokers.kafka.dshdemo.dev.kpn-dsh.com.crt
# # Client's key
# ssl.key.location=/home/riaan/dev/certstrap/out/client.of.brokers.kafka.dshdemo.dev.kpn-dsh.com.key

security.protocol=SSL
ssl.truststore.location=./truststore.jks
ssl.truststore.password=whatever
ssl.keystore.location=./keystore.jks
ssl.keystore.password=whatever
# ssl.key.password=

key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

